{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3c3a220b-fbfa-467b-9906-dc04f12b595e",
   "metadata": {},
   "source": [
    "# 2nd April Assignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76e1bfa2-1b6a-4815-83fd-834b24fbff47",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2a022d12-8027-4b11-889b-6d5378c625e4",
   "metadata": {},
   "source": [
    "## Q1. What is the purpose of grid search cv in machine learning, and how does it work?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0076c403-120d-4693-8556-dc68c6000003",
   "metadata": {},
   "source": [
    "- > GridSearch CV is a hyperparameter tuning technique.\n",
    "\n",
    "- > It takes parameters as param grid and try all combination of that parameters on the dataset.\n",
    "\n",
    "- > After fit the grid search cv on the data we can find best parameters among all.\n",
    "\n",
    "- > Grid search cv helps us to train our model in best way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ca7b539-c8dd-4cb1-9cb4-6f976494e39a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5bff6eff-0b46-4e8e-9299-00f16f708a2c",
   "metadata": {},
   "source": [
    "## Q2. Describe the difference between grid search cv and randomize search cv, and when might you choose one over the other?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6cf227f-ec6b-4711-b4e9-816748c8019c",
   "metadata": {},
   "source": [
    "- > Grid search cv try all combinations of parameters.\n",
    "\n",
    "- > Randomized search cv take input called n_iter.It try random combination of entered value in n_iter.\n",
    "\n",
    "- > We should use grid search cv when size of dataset is small.\n",
    "\n",
    "- > We should use randomized search cv when size of dataset is huge.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd22e0ad-370f-4195-9e11-6287d4558cc1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e79c40dd-bea1-46fe-9e16-14c4e7159560",
   "metadata": {},
   "source": [
    "## Q3. What is data leakage, and why is it a problem in machine learning? Provide an example."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5505331-505d-47e4-8a8a-b140ec86f8d4",
   "metadata": {},
   "source": [
    "* Data Leakage\n",
    "\n",
    "- > Data leakage in context of machine learning is unintentional exposure of information from train dataset to model while training process.\n",
    "\n",
    "- > Because of leakage model will perform will for training dataset but poor for new real world data.\n",
    "\n",
    "* Example\n",
    "\n",
    "- > Consider a machine learning model for detecting credit card fraud. The dataset contains information about legitimate transactions and fraudulent transactions. Suppose the dataset includes a feature that represents the transaction date. If this feature is used in the model, and the data is not properly split chronologically into training and test sets, the model may learn patterns associated with the specific dates in the training set.\n",
    "\n",
    "- > Now, if the model is evaluated on a test set that includes transactions from later dates, it might not generalize well because it has learned patterns specific to the temporal characteristics of the training set. This is an example of temporal leakage and could result in a model that performs poorly in real-world scenarios where the patterns of fraud change over time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2f35b37-48de-49e8-b875-cc70e9b437db",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c1d0d1a8-8064-42b0-9bdb-3bc25ac8d58c",
   "metadata": {},
   "source": [
    "## Q4. How can you prevent data leakage when building a machine learning model?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a155375-f953-40c8-8b07-c2a9789db5bd",
   "metadata": {},
   "source": [
    "- > Preventing data leakage requires careful handling of data, ensuring that information from the test set does not influence the training process. Proper data splitting, feature engineering, and preprocessing are essential to build models that generalize well to new, unseen data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab992899-ee08-474c-9d1f-1df14171d34a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6c848c08-166f-4c05-ab8e-71418def3aaa",
   "metadata": {},
   "source": [
    "## Q5. What is a confusion matrix, and what does it tell you about the performance of a classification model?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eee7ddd2-8fd3-4056-af64-76435acd5b3a",
   "metadata": {},
   "source": [
    "- > Confusion metrix is a table in classification used to evaluate performance of the model.\n",
    "\n",
    "- > Formula : TP + TN / TP + TN + FP + FN\n",
    "\n",
    "- > The confusion matrix helps in understanding where the model excels and where it struggles. For example, a high number of false positives may indicate that the model has a problem with precision, while a high number of false negatives may indicate a recall issue. The choice of which metric to prioritize depends on the specific goals and requirements of the application."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00fb98ee-5127-4b93-9bf2-41c5c9f14390",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "78e5740a-aa1c-41f2-892a-c8a69a9e03ae",
   "metadata": {},
   "source": [
    "## Q6. Explain the difference between precision and recall in the context of a confusion matrix."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01edc57d-5f9a-41cf-b8d6-a568e77ac226",
   "metadata": {},
   "source": [
    "- > Precision is about the accuracy of the positive predictions. It is the proportion of true positives among all instances predicted as positive. Precision is a measure of the model's ability to avoid making false positive predictions.\n",
    "\n",
    "- > Recall is about the completeness of the positive predictions. It is the proportion of true positives among all actual positive instances. Recall is a measure of the model's ability to capture all the positive instances without missing any.\n",
    "\n",
    "- > There is often a trade-off between precision and recall. Increasing one may decrease the other. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d38c7659-9a2a-4727-a037-acda19da68ed",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "30b9685e-1425-4d83-bf69-59fc5335e929",
   "metadata": {},
   "source": [
    "## Q7. How can you interpret a confusion matrix to determine which types of errors your model is making?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b775e7f1-1d64-4a61-ba5e-3fa366ef6e45",
   "metadata": {},
   "source": [
    "- > Interpreting the confunstion metrix is very crucial to understanding performance of model and identify types of error it is making.\n",
    "\n",
    "- > Confusion metrix devides it prediction into four categories : TP , TN , FP , FN .\n",
    "\n",
    "True Positive : Correctly predicted positive value.\n",
    "\n",
    "True Nagitive : Correctly predicted nagitive value.\n",
    "\n",
    "False Positive : Incorrectly predicted positive value.\n",
    "\n",
    "False Nagitive : Incorrectly predicted nagitive value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07519277-2557-4dfb-9327-9bd7bb92ecbe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e21ee39b-9e3f-49b3-8de2-09850ad6826f",
   "metadata": {},
   "source": [
    "## Q8. What are some common metrics that can be derived from a confusion matrix, and how are they calculated?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57e0a506-9cb9-4760-9051-f256c84de0e7",
   "metadata": {},
   "source": [
    "* Some common metrics that can be derived from a confusion matrix :\n",
    "\n",
    "Precision \n",
    "\n",
    "Recall\n",
    "\n",
    "Accuracy\n",
    "\n",
    "F-Score Beta\n",
    "\n",
    "* Calculation\n",
    "\n",
    "Accuracy : total positive + total nagitive / total instances\n",
    "\n",
    "Precision : true positive / true positive + false positive\n",
    "\n",
    "Recall : true positive / true positive + false nagitive\n",
    "\n",
    "F-Score Beta : ( F * Score ) * ( precision * recall / precision + recall )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3224aa23-824d-4e88-bb35-ddb47781d417",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "27434991-a620-4e44-beec-216de58542d8",
   "metadata": {},
   "source": [
    "## Q9. What is the relationship between the accuracy of a model and the values in its confusion matrix?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f345b34f-7edb-44f0-a860-29fd74f7f83e",
   "metadata": {},
   "source": [
    "- > The accuracy of a model is directly related to the values in its confusion matrix. The accuracy is a measure of the overall correctness of predictions, and it considers both true positives (TP) and true negatives (TN) in relation to the total number of instances.\n",
    "\n",
    "Formula : True Positive + True Nagitive / Total Instances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85af1e73-990c-4a10-bd9c-4d5db7137577",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "088db5a8-df68-49ef-8cb9-ea8fa7c6f30d",
   "metadata": {},
   "source": [
    "## Q10. How can you use a confusion matrix to identify potential biases or limitations in your machine learning model?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b21810c-a26e-4eb9-b016-3e34f0f2a53b",
   "metadata": {},
   "source": [
    "- > With help of confusion metrix we can know the false positive and false nagitive.\n",
    "\n",
    "- > FP and FN can make problem in the model's performance.\n",
    "\n",
    "- > If our requirement is to reduce FP so we can use precision.\n",
    "\n",
    "- > If our requirement is to reduce FN so we can use recall."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f55955d8-37ba-432b-bb28-ec35dae57f5b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
